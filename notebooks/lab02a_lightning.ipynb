{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 02a: PyTorch Lightning\n",
    "\n",
    "### What You Will Learn\n",
    "\n",
    "- The core components of a PyTorch Lightning training loop: `LightningModule`s and `Trainer`s.\n",
    "- Useful quality-of-life improvements offered by PyTorch Lightning: `LightningDataModule`s, `Callback`s, and `Metric`s\n",
    "- How we use these features in the FSDL codebase"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amazingguni/git/fsdl-text-recognizer-2022-labs\n",
      "Makefile   \u001b[0m\u001b[01;34mdata\u001b[0m/            \u001b[01;34mnotebooks\u001b[0m/     \u001b[01;34mtext_recognizer\u001b[0m/\n",
      "README.md  environment.yml  \u001b[01;34mrequirements\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "if \"bootstrap\" not in locals() or bootstrap.run:\n",
    "    # path management for Python\n",
    "    pythonpath, = !echo $PYTHONPATH\n",
    "    if \".\" not in pythonpath.split(\":\"):\n",
    "        pythonpath = \".:\" + pythonpath\n",
    "        %env PYTHONPATH={pythonpath}\n",
    "        !echo $PYTHONPATH\n",
    "\n",
    "    # get both Colab and local notebooks into the same state\n",
    "    !wget --quiet https://fsdl.me/gist-bootstrap -O bootstrap.py\n",
    "    import bootstrap\n",
    "\n",
    "    # change into the lab directory\n",
    "    # bootstrap.change_to_lab_dir(lab_idx=lab_idx)\n",
    "\n",
    "    # allow \"hot-reloading\" of modules\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    # needed for inline plots in some contexts\n",
    "    %matplotlib inline\n",
    "\n",
    "    bootstrap.run = False  # change to True re-run setup\n",
    "    \n",
    "!pwd\n",
    "%ls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Lighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://pytorch-lightning.readthedocs.io/en/1.6.3/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "version = pl.__version__\n",
    "\n",
    "docs_url = f\"https://pytorch-lightning.readthedocs.io/en/{version}/\"  # version can also be latest, stable\n",
    "docs_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"720\"\n",
       "            height=\"720\"\n",
       "            src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/pl_docs/pl_mod_vid.m4v\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f09c2ec3250>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython.display as display\n",
    "\n",
    "\n",
    "display.IFrame(src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/pl_docs/pl_mod_vid.m4v\",\n",
    "               width=720, height=720)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `pl.LightningModule`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "issubclass(pl.LightningModule, torch.nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.lit_models import BaseLitModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()  # just like in torch.nn.Module, we need to call the parent class __init__\n",
    "\n",
    "        # attach torch.nn.Modules as top level attributes during init, just like in a torch.nn.Module\n",
    "        self.model = torch.nn.Linear(in_features=1, out_features=1)\n",
    "        # we like to define the entire model as one torch.nn.Module -- typically in a separate class\n",
    "\n",
    "    # optionally, define a forward method\n",
    "    def forward(self, xs):\n",
    "        return self.model(xs)  # we like to just call the model's forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:\n",
      "\tNo `training_step()` method defined. Lightning `Trainer` expects as minimum a\n",
      "\t`training_step()`, `train_dataloader()` and `configure_optimizers()` to be\n",
      "\tdefined.\n"
     ]
    }
   ],
   "source": [
    "import logging  # import some stdlib components to control what's display\n",
    "import textwrap\n",
    "import traceback\n",
    "\n",
    "\n",
    "try:  # try using the LinearRegression LightningModule defined above\n",
    "    logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)  # hide some info for now\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # we'll explain how the Trainer works in a bit\n",
    "    trainer = pl.Trainer(gpus=int(torch.cuda.is_available()), max_epochs=1)\n",
    "    trainer.fit(model=model)  \n",
    "\n",
    "except pl.utilities.exceptions.MisconfigurationException as error:\n",
    "    print(\"Error:\", *textwrap.wrap(str(error), 80), sep=\"\\n\\t\")  # show the error without raising it\n",
    "\n",
    "finally:  # bring back info-level logging\n",
    "    logging.getLogger(\"pytorch_lightning\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def training_step(self: pl.LightningModule, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "    xs, ys = batch\n",
    "    outs = self(xs)\n",
    "    loss = torch.nn.functional.mse_loss(outs, ys)\n",
    "    return loss\n",
    "\n",
    "LinearRegression.training_step = training_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mBaseLitModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Here you compute and return the training loss and some additional metrics for e.g.\n",
      "the progress bar or logger.\n",
      "\n",
      "Args:\n",
      "    batch (:class:`~torch.Tensor` | (:class:`~torch.Tensor`, ...) | [:class:`~torch.Tensor`, ...]):\n",
      "        The output of your :class:`~torch.utils.data.DataLoader`. A tensor, tuple or list.\n",
      "    batch_idx (``int``): Integer displaying index of this batch\n",
      "    optimizer_idx (``int``): When using multiple optimizers, this argument will also be present.\n",
      "    hiddens (``Any``): Passed in if\n",
      "        :paramref:`~pytorch_lightning.core.lightning.LightningModule.truncated_bptt_steps` > 0.\n",
      "\n",
      "Return:\n",
      "    Any of.\n",
      "\n",
      "    - :class:`~torch.Tensor` - The loss tensor\n",
      "    - ``dict`` - A dictionary. Can include any keys, but must include the key ``'loss'``\n",
      "    - ``None`` - Training will skip to the next batch. This is only for automatic optimization.\n",
      "        This is not supported for multi-GPU, TPU, IPU, or DeepSpeed.\n",
      "\n",
      "In this step you'd normally do the forward pass and calculate the loss for a batch.\n",
      "You can also do fancier things like multiple forward passes or something model specific.\n",
      "\n",
      "Example::\n",
      "\n",
      "    def training_step(self, batch, batch_idx):\n",
      "        x, y, z = batch\n",
      "        out = self.encoder(x)\n",
      "        loss = self.loss(out, x)\n",
      "        return loss\n",
      "\n",
      "If you define multiple optimizers, this step will be called with an additional\n",
      "``optimizer_idx`` parameter.\n",
      "\n",
      ".. code-block:: python\n",
      "\n",
      "    # Multiple optimizers (e.g.: GANs)\n",
      "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
      "        if optimizer_idx == 0:\n",
      "            # do training_step with encoder\n",
      "            ...\n",
      "        if optimizer_idx == 1:\n",
      "            # do training_step with decoder\n",
      "            ...\n",
      "\n",
      "\n",
      "If you add truncated back propagation through time you will also get an additional\n",
      "argument with the hidden states of the previous step.\n",
      "\n",
      ".. code-block:: python\n",
      "\n",
      "    # Truncated back-propagation through time\n",
      "    def training_step(self, batch, batch_idx, hiddens):\n",
      "        # hiddens are the hidden states from the previous truncated backprop step\n",
      "        out, hiddens = self.lstm(data, hiddens)\n",
      "        loss = ...\n",
      "        return {\"loss\": loss, \"hiddens\": hiddens}\n",
      "\n",
      "Note:\n",
      "    The loss value shown in the progress bar is smoothed (averaged) over the last values,\n",
      "    so it differs from the actual loss returned in train/validation step.\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/acc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/git/fsdl-text-recognizer-2022-labs/text_recognizer/lit_models/base.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "BaseLitModel.training_step??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_optimizers(self: LinearRegression) -> torch.optim.Optimizer:\n",
    "    optimizer = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
    "    return optimizer\n",
    "\n",
    "LinearRegression.configure_optimizers = configure_optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mBaseLitModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Choose what optimizers and learning-rate schedulers to use in your optimization.\n",
      "Normally you'd need one. But in the case of GANs or similar you might have multiple.\n",
      "\n",
      "Return:\n",
      "    Any of these 6 options.\n",
      "\n",
      "    - **Single optimizer**.\n",
      "    - **List or Tuple** of optimizers.\n",
      "    - **Two lists** - The first list has multiple optimizers, and the second has multiple LR schedulers\n",
      "      (or multiple ``lr_scheduler_config``).\n",
      "    - **Dictionary**, with an ``\"optimizer\"`` key, and (optionally) a ``\"lr_scheduler\"``\n",
      "      key whose value is a single LR scheduler or ``lr_scheduler_config``.\n",
      "    - **Tuple of dictionaries** as described above, with an optional ``\"frequency\"`` key.\n",
      "    - **None** - Fit will run without any optimizer.\n",
      "\n",
      "The ``lr_scheduler_config`` is a dictionary which contains the scheduler and its associated configuration.\n",
      "The default configuration is shown below.\n",
      "\n",
      ".. code-block:: python\n",
      "\n",
      "    lr_scheduler_config = {\n",
      "        # REQUIRED: The scheduler instance\n",
      "        \"scheduler\": lr_scheduler,\n",
      "        # The unit of the scheduler's step size, could also be 'step'.\n",
      "        # 'epoch' updates the scheduler on epoch end whereas 'step'\n",
      "        # updates it after a optimizer update.\n",
      "        \"interval\": \"epoch\",\n",
      "        # How many epochs/steps should pass between calls to\n",
      "        # `scheduler.step()`. 1 corresponds to updating the learning\n",
      "        # rate after every epoch/step.\n",
      "        \"frequency\": 1,\n",
      "        # Metric to to monitor for schedulers like `ReduceLROnPlateau`\n",
      "        \"monitor\": \"val_loss\",\n",
      "        # If set to `True`, will enforce that the value specified 'monitor'\n",
      "        # is available when the scheduler is updated, thus stopping\n",
      "        # training if not found. If set to `False`, it will only produce a warning\n",
      "        \"strict\": True,\n",
      "        # If using the `LearningRateMonitor` callback to monitor the\n",
      "        # learning rate progress, this keyword can be used to specify\n",
      "        # a custom logged name\n",
      "        \"name\": None,\n",
      "    }\n",
      "\n",
      "When there are schedulers in which the ``.step()`` method is conditioned on a value, such as the\n",
      ":class:`torch.optim.lr_scheduler.ReduceLROnPlateau` scheduler, Lightning requires that the\n",
      "``lr_scheduler_config`` contains the keyword ``\"monitor\"`` set to the metric name that the scheduler\n",
      "should be conditioned on.\n",
      "\n",
      ".. testcode::\n",
      "\n",
      "    # The ReduceLROnPlateau scheduler requires a monitor\n",
      "    def configure_optimizers(self):\n",
      "        optimizer = Adam(...)\n",
      "        return {\n",
      "            \"optimizer\": optimizer,\n",
      "            \"lr_scheduler\": {\n",
      "                \"scheduler\": ReduceLROnPlateau(optimizer, ...),\n",
      "                \"monitor\": \"metric_to_track\",\n",
      "                \"frequency\": \"indicates how often the metric is updated\"\n",
      "                # If \"monitor\" references validation metrics, then \"frequency\" should be set to a\n",
      "                # multiple of \"trainer.check_val_every_n_epoch\".\n",
      "            },\n",
      "        }\n",
      "\n",
      "\n",
      "    # In the case of two optimizers, only one using the ReduceLROnPlateau scheduler\n",
      "    def configure_optimizers(self):\n",
      "        optimizer1 = Adam(...)\n",
      "        optimizer2 = SGD(...)\n",
      "        scheduler1 = ReduceLROnPlateau(optimizer1, ...)\n",
      "        scheduler2 = LambdaLR(optimizer2, ...)\n",
      "        return (\n",
      "            {\n",
      "                \"optimizer\": optimizer1,\n",
      "                \"lr_scheduler\": {\n",
      "                    \"scheduler\": scheduler1,\n",
      "                    \"monitor\": \"metric_to_track\",\n",
      "                },\n",
      "            },\n",
      "            {\"optimizer\": optimizer2, \"lr_scheduler\": scheduler2},\n",
      "        )\n",
      "\n",
      "Metrics can be made available to monitor by simply logging it using\n",
      "``self.log('metric_to_track', metric_val)`` in your :class:`~pytorch_lightning.core.lightning.LightningModule`.\n",
      "\n",
      "Note:\n",
      "    The ``frequency`` value specified in a dict along with the ``optimizer`` key is an int corresponding\n",
      "    to the number of sequential batches optimized with the specific optimizer.\n",
      "    It should be given to none or to all of the optimizers.\n",
      "    There is a difference between passing multiple optimizers in a list,\n",
      "    and passing multiple optimizers in dictionaries with a frequency of 1:\n",
      "\n",
      "        - In the former case, all optimizers will operate on the given batch in each optimization step.\n",
      "        - In the latter, only one optimizer will operate on the given batch at every step.\n",
      "\n",
      "    This is different from the ``frequency`` value specified in the ``lr_scheduler_config`` mentioned above.\n",
      "\n",
      "    .. code-block:: python\n",
      "\n",
      "        def configure_optimizers(self):\n",
      "            optimizer_one = torch.optim.SGD(self.model.parameters(), lr=0.01)\n",
      "            optimizer_two = torch.optim.SGD(self.model.parameters(), lr=0.01)\n",
      "            return [\n",
      "                {\"optimizer\": optimizer_one, \"frequency\": 5},\n",
      "                {\"optimizer\": optimizer_two, \"frequency\": 10},\n",
      "            ]\n",
      "\n",
      "    In this example, the first optimizer will be used for the first 5 steps,\n",
      "    the second optimizer for the next 10 steps and that cycle will continue.\n",
      "    If an LR scheduler is specified for an optimizer using the ``lr_scheduler`` key in the above dict,\n",
      "    the scheduler will only be updated when its optimizer is being used.\n",
      "\n",
      "Examples::\n",
      "\n",
      "    # most cases. no learning rate scheduler\n",
      "    def configure_optimizers(self):\n",
      "        return Adam(self.parameters(), lr=1e-3)\n",
      "\n",
      "    # multiple optimizer case (e.g.: GAN)\n",
      "    def configure_optimizers(self):\n",
      "        gen_opt = Adam(self.model_gen.parameters(), lr=0.01)\n",
      "        dis_opt = Adam(self.model_dis.parameters(), lr=0.02)\n",
      "        return gen_opt, dis_opt\n",
      "\n",
      "    # example with learning rate schedulers\n",
      "    def configure_optimizers(self):\n",
      "        gen_opt = Adam(self.model_gen.parameters(), lr=0.01)\n",
      "        dis_opt = Adam(self.model_dis.parameters(), lr=0.02)\n",
      "        dis_sch = CosineAnnealing(dis_opt, T_max=10)\n",
      "        return [gen_opt, dis_opt], [dis_sch]\n",
      "\n",
      "    # example with step-based learning rate schedulers\n",
      "    # each optimizer has its own scheduler\n",
      "    def configure_optimizers(self):\n",
      "        gen_opt = Adam(self.model_gen.parameters(), lr=0.01)\n",
      "        dis_opt = Adam(self.model_dis.parameters(), lr=0.02)\n",
      "        gen_sch = {\n",
      "            'scheduler': ExponentialLR(gen_opt, 0.99),\n",
      "            'interval': 'step'  # called after each training step\n",
      "        }\n",
      "        dis_sch = CosineAnnealing(dis_opt, T_max=10) # called every epoch\n",
      "        return [gen_opt, dis_opt], [gen_sch, dis_sch]\n",
      "\n",
      "    # example with optimizer frequencies\n",
      "    # see training procedure in `Improved Training of Wasserstein GANs`, Algorithm 1\n",
      "    # https://arxiv.org/abs/1704.00028\n",
      "    def configure_optimizers(self):\n",
      "        gen_opt = Adam(self.model_gen.parameters(), lr=0.01)\n",
      "        dis_opt = Adam(self.model_dis.parameters(), lr=0.02)\n",
      "        n_critic = 5\n",
      "        return (\n",
      "            {'optimizer': dis_opt, 'frequency': n_critic},\n",
      "            {'optimizer': gen_opt, 'frequency': 1}\n",
      "        )\n",
      "\n",
      "Note:\n",
      "    Some things to know:\n",
      "\n",
      "    - Lightning calls ``.backward()`` and ``.step()`` on each optimizer and learning rate scheduler as needed.\n",
      "    - If you use 16-bit precision (``precision=16``), Lightning will automatically handle the optimizers.\n",
      "    - If you use multiple optimizers, :meth:`training_step` will have an additional ``optimizer_idx`` parameter.\n",
      "    - If you use :class:`torch.optim.LBFGS`, Lightning handles the closure function automatically for you.\n",
      "    - If you use multiple optimizers, gradients will be calculated only for the parameters of current optimizer\n",
      "      at each training step.\n",
      "    - If you need to control how often those optimizers step or override the default ``.step()`` schedule,\n",
      "      override the :meth:`optimizer_step` hook.\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;32mdef\u001b[0m \u001b[0mconfigure_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_cycle_max_lr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOneCycleLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_cycle_max_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_cycle_total_steps\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lr_scheduler\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"monitor\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"validation/loss\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/git/fsdl-text-recognizer-2022-labs/text_recognizer/lit_models/base.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "BaseLitModel.configure_optimizers??"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `pl.Traininer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=20, gpus=int(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrelatedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, N=10_000):\n",
    "        self.N = N\n",
    "        self.xs = torch.randn(size=(N, 1))\n",
    "        self.ys = torch.randn_like(self.xs) + self.xs\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.xs[idx], self.ys[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "\n",
    "dataset = CorrelatedDataset()\n",
    "tdl = torch.utils.data.DataLoader(dataset, batch_size=32, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xs:\n",
      "tensor([[ 0.7219],\n",
      "        [ 0.4690],\n",
      "        [-0.1064],\n",
      "        [ 0.4239],\n",
      "        [ 0.8937],\n",
      "        [-0.0726],\n",
      "        [-0.1596],\n",
      "        [ 0.0636],\n",
      "        [ 0.1788],\n",
      "        [ 0.2255]])\n",
      "ys:\n",
      "tensor([[ 0.2742],\n",
      "        [ 1.6060],\n",
      "        [ 0.1574],\n",
      "        [ 0.8369],\n",
      "        [-0.6390],\n",
      "        [-0.9463],\n",
      "        [-0.3240],\n",
      "        [ 1.5056],\n",
      "        [-1.4219],\n",
      "        [ 2.0510]])\n"
     ]
    }
   ],
   "source": [
    "example_xs, example_ys = next(iter(tdl))  # grabbing an example batch to print\n",
    "\n",
    "print(\"xs:\", example_xs[:10], sep=\"\\n\")\n",
    "print(\"ys:\", example_ys[:10], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.DataFrame(data={\"x\": example_xs.flatten(), \"y\": example_ys.flatten()})\\\n",
    "  .plot(x=\"x\", y=\"y\", kind=\"scatter\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: /home/amazingguni/git/fsdl-text-recognizer-2022-labs/lightning_logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss before training: 5.474055290222168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | Linear | 2     \n",
      "---------------------------------\n",
      "2         Trainable params\n",
      "0         Non-trainable params\n",
      "2         Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "/home/amazingguni/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfe96d3f8a9433c9c0fe46aa02371e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after training: 1.2302863597869873\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "print(\"loss before training:\", torch.mean(torch.square(model(dataset.xs) - dataset.ys)).item())\n",
    "\n",
    "trainer.fit(model=model, train_dataloaders=tdl)\n",
    "\n",
    "print(\"loss after training:\", torch.mean(torch.square(model(dataset.xs) - dataset.ys)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = pd.DataFrame(data={\"x\": example_xs.flatten(), \"y\": example_ys.flatten()})\\\n",
    "  .plot(x=\"x\", y=\"y\", legend=True, kind=\"scatter\", label=\"data\")\n",
    "\n",
    "inps = torch.arange(-2, 2, 0.5)[:, None]\n",
    "ax.plot(inps, model(inps).detach(), lw=2, color=\"k\", label=\"predictions\"); ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Customize every aspect of training via flags.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.Trainer.__init__.__doc__.strip().split(\"\\n\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Customize every aspect of training via flags.\n",
      "\n",
      "        Args:\n",
      "\n",
      "            accelerator: Supports passing different accelerator types (\"cpu\", \"gpu\", \"tpu\", \"ipu\", \"hpu\", \"auto\")\n",
      "                as well as custom accelerator instances.\n",
      "\n",
      "                .. deprecated:: v1.5\n",
      "                    Passing training strategies (e.g., 'ddp') to ``accelerator`` has been deprecated in v1.5.0\n",
      "                    and will be removed in v1.7.0. Please use the ``strategy`` argument instead.\n",
      "\n",
      "            accumulate_grad_batches: Accumulates grads every k batches or as set up in the dict.\n",
      "                Default: ``None``.\n",
      "\n",
      "            amp_backend: The mixed precision backend to use (\"native\" or \"apex\").\n",
      "                Default: ``'native''``.\n",
      "\n",
      "            amp_level: The optimization level to use (O1, O2, etc...). By default it will be set to \"O2\"\n",
      "                if ``amp_backend`` is set to \"apex\".\n",
      "\n",
      "            auto_lr_find: If set to True, will make trainer.tune() run a learning rate finder,\n",
      "                trying to optimize initial learning for faster convergence. trainer.tune() method will\n",
      "                set the suggested learning rate in self.lr or self.learning_rate in the LightningModule.\n",
      "                To use a different key set a string instead of True with the key name.\n",
      "                Default: ``False``.\n",
      "\n",
      "            auto_scale_batch_size: If set to True, will `initially` run a batch size\n",
      "                finder trying to find the largest batch size that fits into memory.\n",
      "                The result will be stored in self.batch_size in the LightningModule.\n",
      "                Additionally, can be set to either `power` that estimates the batch size through\n",
      "                a power search or `binsearch` that estimates the batch size through a binary search.\n",
      "                Default: ``False``.\n",
      "\n",
      "            auto_select_gpus: If enabled and ``gpus`` or ``devices`` is an integer, pick available\n",
      "                gpus automatically. This is especially useful when\n",
      "                GPUs are configured to be in \"exclusive mode\", such\n",
      "                that only one process at a time can access them.\n",
      "                Default: ``False``.\n",
      "\n",
      "            benchmark: Sets ``torch.backends.cudnn.benchmark``.\n",
      "                Defaults to ``True`` if :paramref:`~pytorch_lightning.trainer.trainer.Trainer.deterministic`\n",
      "                is ``False``. Overwrite to manually set a different value. Default: ``None``.\n",
      "\n",
      "            callbacks: Add a callback or list of callbacks.\n",
      "                Default: ``None``.\n",
      "\n",
      "            checkpoint_callback: If ``True``, enable checkpointing.\n",
      "                Default: ``None``.\n",
      "\n",
      "                .. deprecated:: v1.5\n",
      "                    ``checkpoint_callback`` has been deprecated in v1.5 and will be removed in v1.7.\n",
      "                    Please consider using ``enable_checkpointing`` instead.\n",
      "\n",
      "            enable_checkpointing: If ``True``, enable checkpointing.\n",
      "                It will configure a default ModelCheckpoint callback if there is no user-defined ModelCheckpoint in\n",
      "                :paramref:`~pytorch_lightning.trainer.trainer.Trainer.callbacks`.\n",
      "                Default: ``True``.\n",
      "\n",
      "            check_val_every_n_epoch: Check val every n train epochs.\n",
      "                Default: ``1``.\n",
      "\n",
      "\n",
      "            default_root_dir: Default path for logs and weights when no logger/ckpt_callback passed.\n",
      "                Default: ``os.getcwd()``.\n",
      "                Can be remote file paths such as `s3://mybucket/path` or 'hdfs://path/'\n",
      "\n",
      "            detect_anomaly: Enable anomaly detection for the autograd engine.\n",
      "                Default: ``False``.\n",
      "\n",
      "            deterministic: If ``True``, sets whether PyTorch operations must use deterministic algorithms.\n",
      "                Default: ``False``.\n",
      "\n",
      "            devices: Will be mapped to either `gpus`, `tpu_cores`, `num_processes` or `ipus`,\n",
      "                based on the accelerator type.\n",
      "\n",
      "            fast_dev_run: Runs n if set to ``n`` (int) else 1 if set to ``True`` batch(es)\n",
      "                of train, val and test to find any bugs (ie: a sort of unit test).\n",
      "                Default: ``False``.\n",
      "\n",
      "            flush_logs_every_n_steps: How often to flush logs to disk (defaults to every 100 steps).\n",
      "\n",
      "                .. deprecated:: v1.5\n",
      "                    ``flush_logs_every_n_steps`` has been deprecated in v1.5 and will be removed in v1.7.\n",
      "                    Please configure flushing directly in the logger instead.\n",
      "\n",
      "            gpus: Number of GPUs to train on (int) or which GPUs to train on (list or str) applied per node\n",
      "                Default: ``None``.\n",
      "\n",
      "            gradient_clip_val: The value at which to clip gradients. Passing ``gradient_clip_val=None`` disables\n",
      "                gradient clipping. If using Automatic Mixed Precision (AMP), the gradients will be unscaled before.\n",
      "                Default: ``None``.\n",
      "\n",
      "            gradient_clip_algorithm: The gradient clipping algorithm to use. Pass ``gradient_clip_algorithm=\"value\"``\n",
      "                to clip by value, and ``gradient_clip_algorithm=\"norm\"`` to clip by norm. By default it will\n",
      "                be set to ``\"norm\"``.\n",
      "\n",
      "            limit_train_batches: How much of training dataset to check (float = fraction, int = num_batches).\n",
      "                Default: ``1.0``.\n",
      "\n",
      "            limit_val_batches: How much of validation dataset to check (float = fraction, int = num_batches).\n",
      "                Default: ``1.0``.\n",
      "\n",
      "            limit_test_batches: How much of test dataset to check (float = fraction, int = num_batches).\n",
      "                Default: ``1.0``.\n",
      "\n",
      "            limit_predict_batches: How much of prediction dataset to check (float = fraction, int = num_batches).\n",
      "                Default: ``1.0``.\n",
      "\n",
      "            logger: Logger (or iterable collection of loggers) for experiment tracking. A ``True`` value uses\n",
      "                the default ``TensorBoardLogger``. ``False`` will disable logging. If multiple loggers are\n",
      "                provided and the `save_dir` property of that logger is not set, local files (checkpoints,\n",
      "                profiler traces, etc.) are saved in ``default_root_dir`` rather than in the ``log_dir`` of any\n",
      "                of the individual loggers.\n",
      "                Default: ``True``.\n",
      "\n",
      "            log_gpu_memory: None, 'min_max', 'all'. Might slow performance.\n",
      "\n",
      "                .. deprecated:: v1.5\n",
      "                    Deprecated in v1.5.0 and will be removed in v1.7.0\n",
      "                    Please use the ``DeviceStatsMonitor`` callback directly instead.\n",
      "\n",
      "            log_every_n_steps: How often to log within steps.\n",
      "                Default: ``50``.\n",
      "\n",
      "            prepare_data_per_node: If True, each LOCAL_RANK=0 will call prepare data.\n",
      "                Otherwise only NODE_RANK=0, LOCAL_RANK=0 will prepare data\n",
      "\n",
      "                .. deprecated:: v1.5\n",
      "                    Deprecated in v1.5.0 and will be removed in v1.7.0\n",
      "                    Please set ``prepare_data_per_node`` in ``LightningDataModule`` and/or\n",
      "                    ``LightningModule`` directly instead.\n",
      "\n",
      "            process_position: Orders the progress bar when running multiple models on same machine.\n",
      "\n",
      "                .. deprecated:: v1.5\n",
      "                    ``process_position`` has been deprecated in v1.5 and will be removed in v1.7.\n",
      "                    Please pass :class:`~pytorch_lightning.callbacks.progress.TQDMProgressBar` with ``process_position``\n",
      "                    directly to the Trainer's ``callbacks`` argument instead.\n",
      "\n",
      "            progress_bar_refresh_rate: How often to refresh progress bar (in steps). Value ``0`` disables progress bar.\n",
      "                Ignored when a custom progress bar is passed to :paramref:`~Trainer.callbacks`. Default: None, means\n",
      "                a suitable value will be chosen based on the environment (terminal, Google COLAB, etc.).\n",
      "\n",
      "                .. deprecated:: v1.5\n",
      "                    ``progress_bar_refresh_rate`` has been deprecated in v1.5 and will be removed in v1.7.\n",
      "                    Please pass :class:`~pytorch_lightning.callbacks.progress.TQDMProgressBar` with ``refresh_rate``\n",
      "                    directly to the Trainer's ``callbacks`` argument instead. To disable the progress bar,\n",
      "                    pass ``enable_progress_bar = False`` to the Trainer.\n",
      "\n",
      "            enable_progress_bar: Whether to enable to progress bar by default.\n",
      "                Default: ``False``.\n",
      "\n",
      "            profiler: To profile individual steps during training and assist in identifying bottlenecks.\n",
      "                Default: ``None``.\n",
      "\n",
      "            overfit_batches: Overfit a fraction of training data (float) or a set number of batches (int).\n",
      "                Default: ``0.0``.\n",
      "\n",
      "            plugins: Plugins allow modification of core behavior like ddp and amp, and enable custom lightning plugins.\n",
      "                Default: ``None``.\n",
      "\n",
      "            precision: Double precision (64), full precision (32), half precision (16) or bfloat16 precision (bf16).\n",
      "                Can be used on CPU, GPU, TPUs, HPUs or IPUs.\n",
      "                Default: ``32``.\n",
      "\n",
      "            max_epochs: Stop training once this number of epochs is reached. Disabled by default (None).\n",
      "                If both max_epochs and max_steps are not specified, defaults to ``max_epochs = 1000``.\n",
      "                To enable infinite training, set ``max_epochs = -1``.\n",
      "\n",
      "            min_epochs: Force training for at least these many epochs. Disabled by default (None).\n",
      "\n",
      "            max_steps: Stop training after this number of steps. Disabled by default (-1). If ``max_steps = -1``\n",
      "                and ``max_epochs = None``, will default to ``max_epochs = 1000``. To enable infinite training, set\n",
      "                ``max_epochs`` to ``-1``.\n",
      "\n",
      "            min_steps: Force training for at least these number of steps. Disabled by default (``None``).\n",
      "\n",
      "            max_time: Stop training after this amount of time has passed. Disabled by default (``None``).\n",
      "                The time duration can be specified in the format DD:HH:MM:SS (days, hours, minutes seconds), as a\n",
      "                :class:`datetime.timedelta`, or a dictionary with keys that will be passed to\n",
      "                :class:`datetime.timedelta`.\n",
      "\n",
      "            num_nodes: Number of GPU nodes for distributed training.\n",
      "                Default: ``1``.\n",
      "\n",
      "            num_processes: Number of processes for distributed training with ``accelerator=\"cpu\"``.\n",
      "                Default: ``1``.\n",
      "\n",
      "            num_sanity_val_steps: Sanity check runs n validation batches before starting the training routine.\n",
      "                Set it to `-1` to run all batches in all validation dataloaders.\n",
      "                Default: ``2``.\n",
      "\n",
      "            reload_dataloaders_every_n_epochs: Set to a non-negative integer to reload dataloaders every n epochs.\n",
      "                Default: ``0``.\n",
      "\n",
      "            replace_sampler_ddp: Explicitly enables or disables sampler replacement. If not specified this\n",
      "                will toggled automatically when DDP is used. By default it will add ``shuffle=True`` for\n",
      "                train sampler and ``shuffle=False`` for val/test sampler. If you want to customize it,\n",
      "                you can set ``replace_sampler_ddp=False`` and add your own distributed sampler.\n",
      "\n",
      "            resume_from_checkpoint: Path/URL of the checkpoint from which training is resumed. If there is\n",
      "                no checkpoint file at the path, an exception is raised. If resuming from mid-epoch checkpoint,\n",
      "                training will start from the beginning of the next epoch.\n",
      "\n",
      "                .. deprecated:: v1.5\n",
      "                    ``resume_from_checkpoint`` is deprecated in v1.5 and will be removed in v2.0.\n",
      "                    Please pass the path to ``Trainer.fit(..., ckpt_path=...)`` instead.\n",
      "\n",
      "            strategy: Supports different training strategies with aliases\n",
      "                as well custom strategies.\n",
      "                Default: ``None``.\n",
      "\n",
      "            sync_batchnorm: Synchronize batch norm layers between process groups/whole world.\n",
      "                Default: ``False``.\n",
      "\n",
      "            terminate_on_nan: If set to True, will terminate training (by raising a `ValueError`) at the\n",
      "                end of each training batch, if any of the parameters or the loss are NaN or +/-inf.\n",
      "\n",
      "                .. deprecated:: v1.5\n",
      "                    Trainer argument ``terminate_on_nan`` was deprecated in v1.5 and will be removed in 1.7.\n",
      "                    Please use ``detect_anomaly`` instead.\n",
      "\n",
      "            detect_anomaly: Enable anomaly detection for the autograd engine.\n",
      "                Default: ``False``.\n",
      "\n",
      "            tpu_cores: How many TPU cores to train on (1 or 8) / Single TPU to train on (1)\n",
      "                Default: ``None``.\n",
      "\n",
      "            ipus: How many IPUs to train on.\n",
      "                Default: ``None``.\n",
      "\n",
      "            track_grad_norm: -1 no tracking. Otherwise tracks that p-norm. May be set to 'inf' infinity-norm. If using\n",
      "                Automatic Mixed Precision (AMP), the gradients will be unscaled before logging them.\n",
      "                Default: ``-1``.\n",
      "\n",
      "            val_check_interval: How often to check the validation set. Pass a ``float`` in the range [0.0, 1.0] to check\n",
      "                after a fraction of the training epoch. Pass an ``int`` to check after a fixed number of training\n",
      "                batches.\n",
      "                Default: ``1.0``.\n",
      "\n",
      "            enable_model_summary: Whether to enable model summarization by default.\n",
      "                Default: ``True``.\n",
      "\n",
      "            weights_summary: Prints a summary of the weights when training begins.\n",
      "\n",
      "                .. deprecated:: v1.5\n",
      "                    ``weights_summary`` has been deprecated in v1.5 and will be removed in v1.7.\n",
      "                    To disable the summary, pass ``enable_model_summary = False`` to the Trainer.\n",
      "                    To customize the summary, pass :class:`~pytorch_lightning.callbacks.model_summary.ModelSummary`\n",
      "                    directly to the Trainer's ``callbacks`` argument.\n",
      "\n",
      "            weights_save_path: Where to save weights if specified. Will override default_root_dir\n",
      "                for checkpoints only. Use this if for whatever reason you need the checkpoints\n",
      "                stored in a different place than the logs written in `default_root_dir`.\n",
      "                Can be remote file paths such as `s3://mybucket/path` or 'hdfs://path/'\n",
      "                Defaults to `default_root_dir`.\n",
      "\n",
      "                .. deprecated:: v1.6\n",
      "                    ``weights_save_path`` has been deprecated in v1.6 and will be removed in v1.8. Please pass\n",
      "                    ``dirpath`` directly to the :class:`~pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint`\n",
      "                    callback.\n",
      "\n",
      "            move_metrics_to_cpu: Whether to force internal logged metrics to be moved to cpu.\n",
      "                This can save some gpu memory, but can make training slower. Use with attention.\n",
      "                Default: ``False``.\n",
      "\n",
      "            multiple_trainloader_mode: How to loop over the datasets when there are multiple train loaders.\n",
      "                In 'max_size_cycle' mode, the trainer ends one epoch when the largest dataset is traversed,\n",
      "                and smaller datasets reload when running out of their data. In 'min_size' mode, all the datasets\n",
      "                reload when reaching the minimum length of datasets.\n",
      "                Default: ``\"max_size_cycle\"``.\n",
      "\n",
      "            stochastic_weight_avg: Whether to use `Stochastic Weight Averaging (SWA)\n",
      "                <https://pytorch.org/blog/pytorch-1.6-now-includes-stochastic-weight-averaging/>`_.\n",
      "                Default: ``False``.\n",
      "\n",
      "                .. deprecated:: v1.5\n",
      "                    ``stochastic_weight_avg`` has been deprecated in v1.5 and will be removed in v1.7.\n",
      "                    Please pass :class:`~pytorch_lightning.callbacks.stochastic_weight_avg.StochasticWeightAveraging`\n",
      "                    directly to the Trainer's ``callbacks`` argument instead.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(pl.Trainer.__init__.__doc__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with PyTorch Lightning in the FSDL Codebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py  __pycache__  base.py\n"
     ]
    }
   ],
   "source": [
    "!ls text_recognizer/lit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py  __pycache__  run_experiment.py  util.py\n"
     ]
    }
   ],
   "source": [
    "!ls training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment-running framework. \n",
      "    Run an experiment.\n",
      "\n",
      "    Sample command:\n",
      "    ```\n",
      "    python training/run_experiment.py --max_epochs=3 --gpus='0,' --num_workers=20 --model_class=MLP --data_class=MNIST\n",
      "    ```\n",
      "\n",
      "    For basic help documentation, run the command\n",
      "    ```\n",
      "    python training/run_experiment.py --help\n",
      "    ```\n",
      "\n",
      "    The available command line args differ depending on some of the arguments, including --model_class and --data_class.\n",
      "\n",
      "    To see which command line args are available and read their documentation, provide values for those arguments\n",
      "    before invoking --help, like so:\n",
      "    ```\n",
      "    python training/run_experiment.py --model_class=MLP --data_class=MNIST --help\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import training.run_experiment\n",
    "\n",
    "\n",
    "print(training.run_experiment.__doc__, training.run_experiment.main.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    trainer = pl.Trainer.from_argparse_args(args, callbacks=callbacks, logger=logger)\n"
     ]
    }
   ],
   "source": [
    "# how the trainer is initialized in the training script\n",
    "!grep \"pl.Trainer.from\" training/run_experiment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl.Trainer:\n",
      "  --logger [LOGGER]     Logger (or iterable collection of loggers) for\n",
      "                        experiment tracking. A ``True`` value uses the default\n",
      "                        ``TensorBoardLogger``. ``False`` will disable logging.\n",
      "                        If multiple loggers are provided and the `save_dir`\n",
      "                        property of that logger is not set, local files\n",
      "                        (checkpoints, profiler traces, etc.) are saved in\n",
      "                        ``default_root_dir`` rather than in the ``log_dir`` of\n",
      "                        any of the individual loggers. Default: ``True``.\n",
      "  --checkpoint_callback [CHECKPOINT_CALLBACK]\n",
      "                        If ``True``, enable checkpointing. Default: ``None``.\n",
      "                        .. deprecated:: v1.5 ``checkpoint_callback`` has been\n",
      "                        deprecated in v1.5 and will be removed in v1.7. Please\n",
      "                        consider using ``enable_checkpointing`` instead.\n",
      "  --enable_checkpointing [ENABLE_CHECKPOINTING]\n",
      "                        If ``True``, enable checkpointing. It will configure a\n",
      "                        default ModelCheckpoint callback if there is no user-\n",
      "                        defined ModelCheckpoint in :paramref:`~pytorch_lightni\n",
      "                        ng.trainer.trainer.Trainer.callbacks`. Default:\n",
      "                        ``True``.\n",
      "  --default_root_dir DEFAULT_ROOT_DIR\n",
      "                        Default path for logs and weights when no\n",
      "                        logger/ckpt_callback passed. Default: ``os.getcwd()``.\n",
      "                        Can be remote file paths such as `s3://mybucket/path`\n",
      "                        or 'hdfs://path/'\n"
     ]
    }
   ],
   "source": [
    "# displays the first few flags for controlling the Trainer from the command line\n",
    "!python training/run_experiment.py --help | grep \"pl.Trainer\" -A 24"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Goodies\n",
    "\n",
    "We'll cover three more here:\n",
    "- `pl.LightningDataModule`s, for organizing dataloaders and handling data in distributed settings\n",
    "- `pl.Callback`s, for adding \"optional\" extra features to model training\n",
    "- `torchmetrics`, for efficiently computing and logging "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pl.LightningDataModule`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class CorrelatedDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, size=10_000, train_frac=0.8, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.train_frac, self.val_frac = train_frac, 1-train_frac\n",
    "        self.train_indices = list(range(math.floor(self.size * train_frac)))\n",
    "        self.val_indices = list(range(self.train_indices[-1], self.size))\n",
    "        self.dataset = CorrelatedDataset(N=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(self, stage=None):  # prepares state that needs to be set for each GPU on each node\n",
    "    if stage == \"fit\" or stage is None:  # other stages: \"test\", \"predict\"\n",
    "        self.train_dataset = torch.utils.data.Subset(self.dataset, self.train_indices)\n",
    "        self.val_dataset = torch.utils.data.Subset(self.dataset, self.val_indices)\n",
    "\n",
    "def prepare_data(self):  # prepares state that needs to be set once per node\n",
    "    pass  # but we don't have any \"node-level\" computations\n",
    "\n",
    "\n",
    "CorrelatedDataModule.setup, CorrelatedDataModule.prepare_data = setup, prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dataloader(self: pl.LightningDataModule) -> torch.utils.data.DataLoader:\n",
    "    return torch.utils.data.DataLoader(self.train_dataset, batch_size=32)\n",
    "\n",
    "def val_dataloader(self: pl.LightningDataModule) -> torch.utils.data.DataLoader:\n",
    "    return torch.utils.data.DataLoader(self.val_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "CorrelatedDataModule.train_dataloader, CorrelatedDataModule.val_dataloader = train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/amazingguni/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:131: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | Linear | 2     \n",
      "---------------------------------\n",
      "2         Trainable params\n",
      "0         Non-trainable params\n",
      "2         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss before training: 4.887789726257324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amazingguni/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e1dc74f56544c9acc00d06bc496941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after training: 2.4029362201690674\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "datamodule = CorrelatedDataModule()\n",
    "dataset = datamodule.dataset\n",
    "\n",
    "print(\"loss before training:\", torch.mean(torch.square(model(dataset.xs) - dataset.ys)).item())\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=10, gpus=int(torch.cuda.is_available()))\n",
    "trainer.fit(model=model, datamodule=datamodule)\n",
    "\n",
    "print(\"loss after training:\", torch.mean(torch.square(model(dataset.xs) - dataset.ys)).item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pl.Callback`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hooks:\n",
      "\ton_after_backward, on_batch_end, on_batch_start,\n",
      "\ton_before_accelerator_backend_setup, on_before_backward,\n",
      "\ton_before_optimizer_step, on_before_zero_grad, on_configure_sharded_model,\n",
      "\ton_epoch_end, on_epoch_start, on_exception, on_fit_end, on_fit_start,\n",
      "\ton_init_end, on_init_start, on_keyboard_interrupt, on_load_checkpoint,\n",
      "\ton_predict_batch_end, on_predict_batch_start, on_predict_end,\n",
      "\ton_predict_epoch_end, on_predict_epoch_start, on_predict_start,\n",
      "\ton_pretrain_routine_end, on_pretrain_routine_start, on_sanity_check_end,\n",
      "\ton_sanity_check_start, on_save_checkpoint, on_test_batch_end,\n",
      "\ton_test_batch_start, on_test_end, on_test_epoch_end, on_test_epoch_start,\n",
      "\ton_test_start, on_train_batch_end, on_train_batch_start, on_train_end,\n",
      "\ton_train_epoch_end, on_train_epoch_start, on_train_start,\n",
      "\ton_validation_batch_end, on_validation_batch_start, on_validation_end,\n",
      "\ton_validation_epoch_end, on_validation_epoch_start, on_validation_start\n"
     ]
    }
   ],
   "source": [
    "hooks = \", \".join([method for method in dir(pl.Callback) if method.startswith(\"on_\")])\n",
    "print(\"hooks:\", *textwrap.wrap(hooks, width=80), sep=\"\\n\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HelloWorldCallback(pl.Callback):\n",
    "\n",
    "    def on_train_epoch_start(self, trainer: pl.Trainer, pl_module: pl.LightningModule):\n",
    "        print(\" hello from the start of the training epoch!\")\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer: pl.Trainer, pl_module: pl.LightningModule):\n",
    "        print(\" hello from the end of the validation epoch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def on_train_batch_start(self, trainer: pl.Trainer, pl_module: pl.LightningModule, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int):\n",
    "        if random.random() > 0.995:\n",
    "            print(f\" hello from inside the lucky batch, #{batch_idx}!\")\n",
    "\n",
    "\n",
    "HelloWorldCallback.on_train_batch_start = on_train_batch_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "datamodule = CorrelatedDataModule()\n",
    "\n",
    "trainer = pl.Trainer(  # we instantiate and provide the callback here, but nothing happens yet\n",
    "    max_epochs=10, gpus=int(torch.cuda.is_available()), callbacks=[HelloWorldCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | Linear | 2     \n",
      "---------------------------------\n",
      "2         Trainable params\n",
      "0         Non-trainable params\n",
      "2         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9c9f4bb47a4edeb6079564109a63fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hello from the start of the training epoch!\n",
      " hello from inside the lucky batch, #14!\n",
      " hello from the start of the training epoch!\n",
      " hello from the start of the training epoch!\n",
      " hello from inside the lucky batch, #19!\n",
      " hello from inside the lucky batch, #105!\n",
      " hello from the start of the training epoch!\n",
      " hello from inside the lucky batch, #54!\n",
      " hello from inside the lucky batch, #102!\n",
      " hello from inside the lucky batch, #206!\n",
      " hello from the start of the training epoch!\n",
      " hello from inside the lucky batch, #149!\n",
      " hello from inside the lucky batch, #217!\n",
      " hello from inside the lucky batch, #237!\n",
      " hello from the start of the training epoch!\n",
      " hello from the start of the training epoch!\n",
      " hello from inside the lucky batch, #132!\n",
      " hello from inside the lucky batch, #155!\n",
      " hello from inside the lucky batch, #202!\n",
      " hello from inside the lucky batch, #223!\n",
      " hello from the start of the training epoch!\n",
      " hello from the start of the training epoch!\n",
      " hello from inside the lucky batch, #75!\n",
      " hello from inside the lucky batch, #99!\n",
      " hello from the start of the training epoch!\n",
      " hello from inside the lucky batch, #36!\n",
      " hello from inside the lucky batch, #147!\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `torchmetric`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics:\n",
      "\tfunctional, Accuracy, AUC, AUROC, AveragePrecision, BinnedAveragePrecision,\n",
      "\tBinnedPrecisionRecallCurve, BinnedRecallAtFixedPrecision, BLEUScore,\n",
      "\tBootStrapper, CalibrationError, CatMetric, CHRFScore, CohenKappa,\n",
      "\tConfusionMatrix, CosineSimilarity, TweedieDevianceScore, ExplainedVariance,\n",
      "\tExtendedEditDistance, F1, F1Score, FBeta, FBetaScore, HammingDistance, Hinge,\n",
      "\tHingeLoss, JaccardIndex, KLDivergence, MatthewsCorrcoef, MatthewsCorrCoef,\n",
      "\tMaxMetric, MeanAbsoluteError, MeanAbsolutePercentageError, MeanMetric,\n",
      "\tMeanSquaredError, MeanSquaredLogError, Metric, MetricCollection, MetricTracker,\n",
      "\tMinMaxMetric, MinMetric, MultioutputWrapper,\n",
      "\tMultiScaleStructuralSimilarityIndexMeasure, PearsonCorrcoef, PearsonCorrCoef,\n",
      "\tPermutationInvariantTraining, PIT, Precision, PrecisionRecallCurve, PSNR,\n",
      "\tPeakSignalNoiseRatio, R2Score, Recall, RetrievalFallOut, RetrievalHitRate,\n",
      "\tRetrievalMAP, RetrievalMRR, RetrievalNormalizedDCG, RetrievalPrecision,\n",
      "\tRetrievalRecall, RetrievalRPrecision, ROC, SacreBLEUScore, SDR,\n",
      "\tSignalDistortionRatio, ScaleInvariantSignalDistortionRatio, SI_SDR, SI_SNR,\n",
      "\tScaleInvariantSignalNoiseRatio, SignalNoiseRatio, SNR, SpearmanCorrcoef,\n",
      "\tSpearmanCorrCoef, Specificity, SQuAD, SSIM, StructuralSimilarityIndexMeasure,\n",
      "\tStatScores, SumMetric, SymmetricMeanAbsolutePercentageError,\n",
      "\tTranslationEditRate, WER, WordErrorRate, CharErrorRate, MatchErrorRate,\n",
      "\tWordInfoLost, WordInfoPreserved\n"
     ]
    }
   ],
   "source": [
    "import torchmetrics\n",
    "\n",
    "\n",
    "tm_version = torchmetrics.__version__\n",
    "print(\"metrics:\", *textwrap.wrap(\", \".join(torchmetrics.__all__), width=80), sep=\"\\n\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issubclass(torchmetrics.Metric, torch.nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mBaseLitModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m Initialize self.  See help(type(self)) for accurate signature.\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mapping\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_dims\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOPTIMIZER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOSS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"transformer\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_cycle_max_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"one_cycle_max_lr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_cycle_total_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"one_cycle_total_steps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mONE_CYCLE_TOTAL_STEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/git/fsdl-text-recognizer-2022-labs/text_recognizer/lit_models/base.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "BaseLitModel.__init__??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def validation_step(self: pl.LightningModule, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "    xs, ys = batch\n",
    "    outs = self(xs)\n",
    "    loss = torch.nn.functional.mse_loss(outs, ys)\n",
    "    self.log(\"validation/loss\", loss, prog_bar=True, sync_dist=True)\n",
    "    return {'loss': loss}\n",
    "    \n",
    "\n",
    "LinearRegression.validation_step = validation_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | Linear | 2     \n",
      "---------------------------------\n",
      "2         Trainable params\n",
      "0         Non-trainable params\n",
      "2         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2d4835884043c1b47ac5c0563f51bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amazingguni/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/amazingguni/miniconda3/envs/fsdl-text-recognizer-2022/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b20a83ae76d4cd8ae1b8f4f01b73c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d251d45c373043558f6f1be0db7bc82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75f379f9970432ebb73e62589d92c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c0323d3efc4c9a944f7484ce9e5063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3614b2492b44688c95cf37d4d61d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbecec45c32e4106b25075af8a6369d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f1993ac6d94fd7a04c76c045fc7aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ef788659fd4cf0b99c98781614bb03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238c854fa19b44a09c2d957939ca81e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132fd2f78b5143ffb352877b5af00201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4f61d536b24750af5dae950dac793c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "datamodule = CorrelatedDataModule()\n",
    "\n",
    "dataset = datamodule.dataset\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=10, gpus=int(torch.cuda.is_available()))\n",
    "# if you code is working, you should see results for the validation loss in the output\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(self: pl.LightningModule, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "    xs, ys = batch\n",
    "    outs = self(xs)\n",
    "    loss = torch.nn.functional.mse_loss(outs, ys)\n",
    "    self.log(\"test/loss\", loss, on_step=False, on_epoch=True)\n",
    "\n",
    "LinearRegression.test_step = test_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrelatedDataModuleWithTest(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, N=10_000, N_test=10_000):  # reimplement __init__ here\n",
    "        super().__init__()  # don't forget this!\n",
    "        self.dataset = None\n",
    "        self.test_dataset = CorrelatedDataset(N=N_test)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        pass\n",
    "\n",
    "    def test_dataloader(self: pl.LightningDataModule) -> torch.utils.data.DataLoader:\n",
    "        return torch.utils.data.DataLoader(self.test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cafd8e2eb294b5d80816ce4d4d09720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test/loss           2.2911384105682373\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test/loss': 2.2911384105682373}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "datamodule = CorrelatedDataModuleWithTest()\n",
    "\n",
    "dataset = datamodule.dataset\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=10, gpus=int(torch.cuda.is_available()))\n",
    "\n",
    "# we run testing without fitting here\n",
    "trainer.test(model=model, datamodule=datamodule)  # if your code is working, you should see performance on the test set here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsdl-text-recognizer-2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd45800261f6757616163cab2ac15de492f098dcc7245a9ac63e943c300526a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
