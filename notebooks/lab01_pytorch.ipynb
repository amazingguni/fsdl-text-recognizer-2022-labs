{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amazingguni/git/fsdl-text-recognizer-2022-labs\n",
      "Makefile   \u001b[0m\u001b[01;34mdata\u001b[0m/            \u001b[01;34mnotebooks\u001b[0m/     \u001b[01;34mtext_recognizer\u001b[0m/\n",
      "README.md  environment.yml  \u001b[01;34mrequirements\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if \"bootstrap\" not in locals() or bootstrap.run:\n",
    "    # path management for Python\n",
    "    pythonpath, = !echo $PYTHONPATH\n",
    "    if \".\" not in pythonpath.split(\":\"):\n",
    "        pythonpath = \".:\" + pythonpath\n",
    "        %env PYTHONPATH={pythonpath}\n",
    "        !echo $PYTHONPATH\n",
    "\n",
    "    # get both Colab and local notebooks into the same state\n",
    "    !wget --quiet https://fsdl.me/gist-bootstrap -O bootstrap.py\n",
    "    import bootstrap\n",
    "\n",
    "    # change into the lab directory\n",
    "    # bootstrap.change_to_lab_dir(lab_idx=lab_idx)\n",
    "\n",
    "    # allow \"hot-reloading\" of modules\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    # needed for inline plots in some contexts\n",
    "    %matplotlib inline\n",
    "\n",
    "    bootstrap.run = False  # change to True re-run setup\n",
    "    \n",
    "!pwd\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_mnist(path):\n",
    "    url = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
    "    filename = \"mnist.pkl.gz\"\n",
    "\n",
    "    if not (path / filename).exists():\n",
    "        content = requests.get(url + filename).content\n",
    "        (path / filename).open(\"wb\").write(content)\n",
    "\n",
    "    return path / filename\n",
    "\n",
    "\n",
    "data_path = Path(\"data\") if Path(\"data\").exists() else Path(\"../data\")\n",
    "path = data_path / \"downloaded\" / \"vector-mnist\"\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "datafile = download_mnist(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "\n",
    "\n",
    "def read_mnist(path):\n",
    "    with gzip.open(path, \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
    "    return x_train, y_train, x_valid, y_valid\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = read_mnist(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([5, 0, 4,  ..., 8, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "print(x_train, y_train, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5),\n",
       " tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0117, 0.0703, 0.4922, 0.6836, 0.6484,\n",
       "         0.9648, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1172, 0.3672,\n",
       "         0.6641, 0.9883, 0.9883, 0.8789, 0.9883, 0.7617, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.9297, 0.9883, 0.9883, 0.9883, 0.9883, 0.3633,\n",
       "         0.3203, 0.1523, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8555,\n",
       "         0.9883, 0.9883, 0.7734, 0.9648, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.3125, 0.4180, 0.9883, 0.0430, 0.1680,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0039, 0.9883, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9883, 0.0078,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.7422, 0.2734, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1367,\n",
       "         0.8789, 0.4219, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9375, 0.9883, 0.0977, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.1758, 0.9883, 0.5859, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3633, 0.9883,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.9883, 0.2500, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1797, 0.7148,\n",
       "         0.9883, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.1523, 0.8945, 0.9883, 0.9766, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0938, 0.8633, 0.9883,\n",
       "         0.9883, 0.3047, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0898, 0.8320, 0.9883, 0.9883, 0.3164, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0703, 0.8555, 0.9883, 0.9883,\n",
       "         0.3125, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.2148, 0.8828, 0.9883, 0.9883, 0.5195, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5312, 0.9883, 0.8281, 0.5156,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0], x_train[0, ::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.ndim, y_train.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(5))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0, 0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 784])\n",
      "torch.Size([50000])\n"
     ]
    }
   ],
   "source": [
    "n, c = x_train.shape\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABjElEQVR4nO3ULavCUBzH8cNVUPcOVAaCsLFgMQ1kiFHwYJssL+wV+AImJrG4siAKRhVErILBZvIVbENhCLPIko9/DYcrwr1e2EO4wW8843z4nTKEPn3yWKlU6na79/sdABqNRiArnU5XKpXJZHK73eC70+mUz+d9isVicbFYXK9XYpmmqeu64zgAgDH2zFWr1dVqRTjDMDqdjiAIsVgMIdRsNv2gPM+7rkvW9Xq9ZDL5+pXjOEVRMpmMBzGbza7XawBwXRdjHI1GaZpWVVVRFG/TXmu1WmRjv98XRVGW5c1mAwCXy6VcLvtENU2DN2ma9u7W19/o4XD49Xy/349GI59LKYqq1Wrj8fh4PD43Oo5TKBR8is9EUXyilmVxHBdUZFnWNE0iLpfLEERJkna7HRGHw2EqlQoqMgxjWRYRZ7NZIpEIKgqCYNs2EdvtNk3TQUWE0GAwIOJ0Oo3H4yGI9Xr9fD4DwHa7ZVk2BDESiRiGQUSGYUIQEUIYY/LwQH+Nn83ncwDI5XJhov+xBymXEfPWdDyYAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28 at 0x7F5804946370>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-execute this cell for more samples\n",
    "import random\n",
    "\n",
    "import wandb  # just for some convenience methods that convert tensors to human-friendly datatypes\n",
    "\n",
    "import text_recognizer.metadata.mnist as metadata # metadata module holds metadata separate from data\n",
    "\n",
    "idx = random.randint(0, len(x_train))\n",
    "example = x_train[idx]\n",
    "\n",
    "print(y_train[idx])  # the label of the image\n",
    "wandb.Image(example.reshape(*metadata.DIMS)).image  # the image itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x: torch.Tensor) -> torch.Tensor:\n",
    "    return x @ weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x: torch.Tensor) -> torch.Tensor:\n",
    "    return x - torch.log(torch.sum(torch.exp(x), axis=1))[:, None]\n",
    "\n",
    "def model(xb: torch.Tensor) -> torch.Tensor:\n",
    "    return log_softmax(linear(xb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.5181, -2.1894, -2.3739, -2.1450, -2.1639, -1.8418, -2.2829, -2.9010,\n",
      "        -2.5495, -2.4220], grad_fn=<SelectBackward0>) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "bs = 64  # batch size\n",
    "\n",
    "xb = x_train[0:bs]  # a batch of inputs\n",
    "outs = model(xb)  # outputs on that batch\n",
    "\n",
    "print(outs[0], outs.shape)  # outputs on the first element of the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defineing the loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out: torch.Tensor, yb: torch.Tensor) -> torch.Tensor:\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1406)\n"
     ]
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "\n",
    "acc = accuracy(outs, yb)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    acc.backward()\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(output: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    return -output[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3227, grad_fn=<NegBackward0>) tensor(2.3026)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(outs, yb), -torch.log(torch.tensor(1 / 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_func(outs, yb)\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0322, -0.0139,  0.0268, -0.0126,  0.0098,  0.0687,  0.0012, -0.0001,\n",
       "        -0.0104, -0.0372])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and running the fitting loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5  # learning rate hyperparameter\n",
    "epochs = 2  # how many epochs to train for\n",
    "for epoch in range(epochs):  # loop over the data repeatedly\n",
    "    for ii in range((n - 1) // bs + 1):  # in batches of size bs, so roughly n / bs of them\n",
    "        start_idx = ii * bs  # we are ii batches in, each of size bs\n",
    "        end_idx = start_idx + bs  # and we want the next bs entires\n",
    "\n",
    "        # pull batches from x and from y\n",
    "        xb = x_train[start_idx:end_idx]\n",
    "        yb = y_train[start_idx:end_idx]\n",
    "\n",
    "        # run model\n",
    "        pred = model(xb)\n",
    "\n",
    "        # get loss\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        # calculate the gradients with a backwards pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update the parameters\n",
    "        with torch.no_grad():  # we don't want to track gradients through this part!\n",
    "            # SGD learning rule: update with negative gradient scaled by lr\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "\n",
    "            # ACHTUNG: PyTorch doesn't assume you're done with gradients\n",
    "            #          until you say so -- by explicitly \"deleting\" them,\n",
    "            #          i.e. setting the gradients to 0.\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0799, grad_fn=<NegBackward0>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAACE0lEQVR4nO2Uv+s5cRzHD58yHF2nrBIGhJKUxHAlpAwSuW5hMOg2u2Qw+QcsZkaFFFHYlCxMSiwMzkAOd/XmO1zJ9/y8+i7fvt/H9H6/X6979Hy/730HQf/561EoFARB5PP56/V6uVwul0u32yUIgiAIhUIhzCWVSlEUTSQSg8EAvKDf78fjcYlE8q2UJMlXLh5qtfqp4Yc312q16XSaGzMMs1qtSJLc7Xa3hkwm4/f7he29Xq9zKXq9XiqVemyQy+WtVut90t8IBoP7/R4AsFwulUrl0x673b5erwVIDQbDdDoFAORyuVc9nU7n45nyyefz7XbbaDQ+lsxmcy6XO51OnLFcLsMw/JX0FTabbT6f895+pVLBMEywy2KxhMPhZrN5Pp+f3iqGYTwejzBpoVC4V7Asy7IsTdM0TTMMwy02Gg3eVyD+0r5YLEqlUjKZJEkShmEYhmOx2OFwgCDI7/dHo1EBSXU6HYZhGIaZTKbH6u2UcRwXIH2Dy+WiKAoAMJvNrFbrHzC63e7VasXFLBaLnx9wOBwqlep9xpsRAIAgyAcjgiCbzWY8Hj969Xq90+kMBALcrjlms5lMJuN1inhzFEUpioIgaDQaDYfD+5LP59NoNPcr2Wy2Wq1OJpMPSUUiUSQS2W63r/6hx+OxVqsVi0UEQcTib28kBEGQ1+vFcRzH8Vqtdm/sdDqhUEiA6J/kF1cTn0zf6deBAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28 at 0x7F58049468E0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-execute this cell for more samples\n",
    "idx = random.randint(0, len(x_train))\n",
    "example = x_train[idx:idx+1]\n",
    "\n",
    "out = model(example)\n",
    "\n",
    "print(out.argmax())\n",
    "wandb.Image(example.reshape(28, 28)).image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactoring with core `torch.nn` components"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `torch.nn.functional` for stateless computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb @ weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0799, grad_fn=<NllLossBackward0>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))  # should be unchanged from above!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `torch.nn.Module` to define functions whose state is given by `torch.nn.Parameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MNISTLogistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3468, -0.3066,  0.1199,  0.0590,  0.0188, -0.5400,  0.6538, -0.5246,\n",
      "          0.3147,  0.0372],\n",
      "        [-0.5542, -0.0786,  0.0962,  0.2127, -0.0057, -0.7853,  0.0979, -0.0108,\n",
      "         -0.1977,  0.1232],\n",
      "        [-0.0902, -0.0947, -0.0314,  0.1709,  0.0954, -0.3542,  0.2334, -0.4118,\n",
      "         -0.0040,  0.5269],\n",
      "        [-0.3461, -0.1720, -0.0455,  0.1757,  0.1872, -0.7587,  0.1104, -0.2399,\n",
      "          0.1718,  0.0114]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 6.7138e-03,  1.3974e-02,  7.0346e-03,  8.7323e-03,  5.4499e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-4.3051e-02,  9.1665e-03,  4.9584e-02,  6.6289e-02, -1.4482e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.4114e-02,  1.7394e-02, -3.8274e-02,  2.7260e-02, -4.3541e-02],\n",
      "        [ 1.6729e-02,  4.0479e-02,  2.0391e-02,  3.1560e-02, -5.6607e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.1445e-02,  2.3823e-02,  4.5630e-02,  6.1521e-02, -2.9120e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.0266e-01,  2.4868e-02,  7.0744e-03,  3.9014e-02, -1.9720e-02],\n",
      "        [-7.0833e-02,  8.0330e-02,  5.5415e-02,  8.2434e-02, -1.2453e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.9958e-02,  4.4721e-02,  2.4625e-02,  3.0163e-02, -5.2139e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.8695e-02,  7.5658e-03,  6.3528e-03,  8.1606e-03,  6.4214e-03],\n",
      "        [ 1.3961e-02,  2.1684e-02, -5.5446e-02,  3.7799e-02, -4.4028e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.9823e-02,  5.3647e-02, -1.6552e-02,  6.9926e-02, -8.0844e-02],\n",
      "        [ 4.9920e-03,  4.4145e-03, -5.3899e-02,  1.1705e-02,  6.7488e-03],\n",
      "        [-2.9111e-02,  5.0015e-03,  3.7901e-03,  5.0037e-03,  3.7150e-03],\n",
      "        [-3.2504e-02, -9.3071e-03, -4.8677e-02,  7.2488e-02,  1.4262e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.7887e-02, -1.7335e-03, -3.8855e-02,  8.5364e-02, -8.9472e-02],\n",
      "        [-5.3862e-02,  9.3330e-03,  8.0051e-03,  1.2361e-02,  5.4362e-03],\n",
      "        [-1.3102e-03,  1.4136e-04,  1.5349e-04,  2.4474e-04,  1.0011e-04],\n",
      "        [-6.1690e-02,  5.4094e-02, -3.9200e-03,  5.5104e-02, -1.1776e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-9.9624e-02,  5.6649e-02, -2.9516e-03,  8.1155e-02, -7.6105e-02],\n",
      "        [-5.3908e-02,  9.2715e-03,  7.9275e-03,  1.2203e-02,  5.3199e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.2290e-01,  4.3278e-02,  8.0714e-02,  1.0947e-01, -1.1922e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2516e-02,  2.0584e-02,  1.4004e-02,  2.3486e-02, -4.6972e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.9051e-04,  7.7718e-04,  1.0451e-03,  1.4690e-03,  6.9295e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "def forward(self, xb: torch.Tensor) -> torch.Tensor:\n",
    "    return xb @ self.weights + self.bias\n",
    "\n",
    "MNISTLogistic.forward = forward\n",
    "\n",
    "model = MNISTLogistic()\n",
    "print(model(xb)[:4])\n",
    "loss = loss_func(model(xb), yb)\n",
    "loss.backward()\n",
    "print(model.weights.grad[::17, ::2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0834, -0.0135, -0.0553,  ..., -0.0027, -0.0338,  0.0384],\n",
      "        [ 0.0386, -0.0114,  0.0355,  ..., -0.0436,  0.0249, -0.0145],\n",
      "        [-0.0152,  0.0375, -0.0030,  ..., -0.0146, -0.0636, -0.0005],\n",
      "        ...,\n",
      "        [ 0.0228, -0.0207,  0.0003,  ..., -0.0394,  0.0045,  0.0476],\n",
      "        [-0.0376, -0.0132,  0.0597,  ...,  0.0159,  0.0091, -0.0372],\n",
      "        [-0.0007, -0.0360, -0.0173,  ...,  0.0334,  0.0003, -0.0288]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(*list(model.parameters()), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for ii in range((n - 1) // bs + 1):\n",
    "            start_idx = ii * bs\n",
    "            end_idx = start_idx + bs\n",
    "            xb = x_train[start_idx:end_idx]\n",
    "            yb = y_train[start_idx:end_idx]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(model(xb), yb))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactoring intermediate `torch.nn` components: network layers, optimizers, and data handling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `torch.nn.Linear` for the model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.nn.Modules:\n",
      "\tModule, Identity, Linear, Conv1d, Conv2d, Conv3d, ConvTranspose1d,\n",
      "\tConvTranspose2d, ConvTranspose3d, Threshold, ReLU, Hardtanh, ReLU6,\n",
      "\tSigmoid, Tanh, Softmax, Softmax2d, LogSoftmax, ELU, SELU, CELU, GLU,\n",
      "\tGELU, Hardshrink, LeakyReLU, LogSigmoid, Softplus, Softshrink,\n",
      "\tMultiheadAttention, PReLU, Softsign, Softmin, Tanhshrink, RReLU,\n",
      "\tL1Loss, NLLLoss, KLDivLoss, MSELoss, BCELoss, BCEWithLogitsLoss,\n",
      "\tNLLLoss2d, PoissonNLLLoss, CosineEmbeddingLoss, CTCLoss,\n",
      "\tHingeEmbeddingLoss, MarginRankingLoss, MultiLabelMarginLoss,\n",
      "\tMultiLabelSoftMarginLoss, MultiMarginLoss, SmoothL1Loss,\n",
      "\tGaussianNLLLoss, HuberLoss, SoftMarginLoss, CrossEntropyLoss,\n",
      "\tContainer, Sequential, ModuleList, ModuleDict, ParameterList,\n",
      "\tParameterDict, AvgPool1d, AvgPool2d, AvgPool3d, MaxPool1d, MaxPool2d,\n",
      "\tMaxPool3d, MaxUnpool1d, MaxUnpool2d, MaxUnpool3d, FractionalMaxPool2d,\n",
      "\tFractionalMaxPool3d, LPPool1d, LPPool2d, LocalResponseNorm,\n",
      "\tBatchNorm1d, BatchNorm2d, BatchNorm3d, InstanceNorm1d, InstanceNorm2d,\n",
      "\tInstanceNorm3d, LayerNorm, GroupNorm, SyncBatchNorm, Dropout,\n",
      "\tDropout1d, Dropout2d, Dropout3d, AlphaDropout, FeatureAlphaDropout,\n",
      "\tReflectionPad1d, ReflectionPad2d, ReflectionPad3d, ReplicationPad2d,\n",
      "\tReplicationPad1d, ReplicationPad3d, CrossMapLRN2d, Embedding,\n",
      "\tEmbeddingBag, RNNBase, RNN, LSTM, GRU, RNNCellBase, RNNCell, LSTMCell,\n",
      "\tGRUCell, PixelShuffle, PixelUnshuffle, Upsample, UpsamplingNearest2d,\n",
      "\tUpsamplingBilinear2d, PairwiseDistance, AdaptiveMaxPool1d,\n",
      "\tAdaptiveMaxPool2d, AdaptiveMaxPool3d, AdaptiveAvgPool1d,\n",
      "\tAdaptiveAvgPool2d, AdaptiveAvgPool3d, TripletMarginLoss, ZeroPad2d,\n",
      "\tConstantPad1d, ConstantPad2d, ConstantPad3d, Bilinear,\n",
      "\tCosineSimilarity, Unfold, Fold, AdaptiveLogSoftmaxWithLoss,\n",
      "\tTransformerEncoder, TransformerDecoder, TransformerEncoderLayer,\n",
      "\tTransformerDecoderLayer, Transformer, LazyLinear, LazyConv1d,\n",
      "\tLazyConv2d, LazyConv3d, LazyConvTranspose1d, LazyConvTranspose2d,\n",
      "\tLazyConvTranspose3d, LazyBatchNorm1d, LazyBatchNorm2d,\n",
      "\tLazyBatchNorm3d, LazyInstanceNorm1d, LazyInstanceNorm2d,\n",
      "\tLazyInstanceNorm3d, Flatten, Unflatten, Hardsigmoid, Hardswish, SiLU,\n",
      "\tMish, TripletMarginWithDistanceLoss, ChannelShuffle\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "print(\"torch.nn.Modules:\", *textwrap.wrap(\", \".join(torch.nn.modules.__all__)), sep=\"\\n\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTLogistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3002, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MNISTLogistic()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(*list(model.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0203, -0.0242, -0.0279,  ...,  0.0171,  0.0031,  0.0149],\n",
      "        [ 0.0230,  0.0005, -0.0246,  ..., -0.0177, -0.0026, -0.0008],\n",
      "        [-0.0308, -0.0247,  0.0303,  ...,  0.0062,  0.0052,  0.0299],\n",
      "        ...,\n",
      "        [-0.0135,  0.0224,  0.0134,  ...,  0.0314,  0.0016,  0.0221],\n",
      "        [-0.0208,  0.0254,  0.0290,  ...,  0.0306,  0.0060, -0.0303],\n",
      "        [-0.0268,  0.0149,  0.0282,  ...,  0.0161, -0.0154, -0.0135]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0344,  0.0098, -0.0019,  0.0087,  0.0170,  0.0077, -0.0193, -0.0235,\n",
      "        -0.0326,  0.0219], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(*list(model.parameters()), sep=\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying gradients with `torch.optim.Optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "def configure_optimizer(model: nn.Module) -> optim.Optimizer:\n",
    "    return optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before training:\n",
      "\ttensor(2.3110, grad_fn=<NllLossBackward0>)\n",
      "after training:\n",
      "\ttensor(0.8484, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MNISTLogistic()\n",
    "opt = configure_optimizer(model)\n",
    "\n",
    "print(\"before training:\", loss_func(model(xb), yb), sep=\"\\n\\t\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for ii in range((n - 1) // bs + 1):\n",
    "        start_idx = ii * bs\n",
    "        end_idx = start_idx + bs\n",
    "        xb = x_train[start_idx:end_idx]\n",
    "        yb = y_train[start_idx:end_idx]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(\"after training:\", loss_func(model(xb), yb), sep=\"\\n\\t\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing data with `torch.utils.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.data.util import BaseDataset\n",
    "\n",
    "train_ds = BaseDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8503, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MNISTLogistic()\n",
    "opt = configure_optimizer(model)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for ii in range((n - 1) // bs + 1):\n",
    "        xb, yb = train_ds[ii * bs: ii * bs + bs]  # xb and yb in one line!\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching up data with `torch.utils.data.DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_ds = BaseDataset(x_train, y_train)\n",
    "train_dataloader = DataLoader(train_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self: nn.Module, train_dataloader: DataLoader):\n",
    "    opt = configure_optimizer(self)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dataloader:\n",
    "            pred = self(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "MNISTLogistic.fit = fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8571, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MNISTLogistic()\n",
    "\n",
    "model.fit(train_dataloader)\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swapping in another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.models.mlp import MLP\n",
    "\n",
    "MLP.fit = fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_dims': (784,),\n",
       " 'mapping': {0: '0',\n",
       "  1: '1',\n",
       "  2: '2',\n",
       "  3: '3',\n",
       "  4: '4',\n",
       "  5: '5',\n",
       "  6: '6',\n",
       "  7: '7',\n",
       "  8: '8',\n",
       "  9: '9'}}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_to_9 = list(range(10))\n",
    "data_config = {'input_dims': (784,), 'mapping': {digit: str(digit) for digit in digits_to_9}}\n",
    "data_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(data_config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 8.7242e-03, -3.1859e-02,  9.0436e-04,  ..., -3.3780e-02,\n",
       "         -3.1793e-02, -1.9702e-03],\n",
       "        [-2.6624e-02,  3.3537e-02,  8.3773e-03,  ...,  1.8987e-02,\n",
       "          5.9025e-03,  1.8216e-03],\n",
       "        [-1.7399e-02, -1.2242e-02, -3.5148e-02,  ..., -2.4685e-02,\n",
       "          2.8347e-02, -1.2276e-02],\n",
       "        ...,\n",
       "        [-7.3215e-03,  3.5017e-02,  3.2381e-03,  ...,  3.5709e-02,\n",
       "          3.5630e-03, -2.7254e-02],\n",
       "        [ 3.5428e-02, -2.5912e-02, -1.7379e-02,  ..., -9.0040e-03,\n",
       "          1.1055e-02, -1.9707e-02],\n",
       "        [ 9.8072e-03, -1.9874e-02, -1.4348e-06,  ..., -4.2096e-03,\n",
       "          2.4742e-02, -2.9996e-02]], requires_grad=True)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before training: tensor(2.3085, grad_fn=<NllLossBackward0>)\n",
      "after training: tensor(0.3510, grad_fn=<NllLossBackward0>)\n",
      "CPU times: user 1min 49s, sys: 51 ms, total: 1min 49s\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"before training:\", loss_func(model(xb), yb))\n",
    "\n",
    "train_ds = BaseDataset(x_train, y_train)\n",
    "train_dataloader = DataLoader(train_ds, batch_size=bs)\n",
    "fit(model, train_dataloader)\n",
    "\n",
    "print(\"after training:\", loss_func(model(xb), yb))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extragoodies: data organization, validation, and acceleration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the GPU go brrrrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 24 10:22:38 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.60.12    Driver Version: 527.41       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| 30%   33C    P8     9W / 200W |   1895MiB /  8192MiB |     20%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A        21      G   /Xwayland                       N/A      |\n",
      "|    0   N/A  N/A        21      G   /Xwayland                       N/A      |\n",
      "|    0   N/A  N/A        23      G   /Xwayland                       N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    print(\"‚òπÔ∏è\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2777, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "loss_func(model(xb.to(device)), yb.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_to_device(tensor):\n",
    "    return tensor.to(device)\n",
    "\n",
    "train_ds = BaseDataset(x_train, y_train, transform=push_to_device, target_transform=push_to_device)\n",
    "train_dataloader = DataLoader(train_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "CPU times: user 13.3 s, sys: 892 ms, total: 14.2 s\n",
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MLP(data_config)\n",
    "model.to(device)\n",
    "\n",
    "model.fit(train_dataloader)\n",
    "\n",
    "print(loss_func(model(push_to_device(xb)), push_to_device(yb)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding validation data and organizing data code with a `DataModule`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule:\n",
    "    url = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
    "    filename = \"mnist.pkl.gz\"\n",
    "    \n",
    "    def __init__(self, dir, bs=32):\n",
    "        self.dir = dir\n",
    "        self.bs = bs\n",
    "        self.path = self.dir / self.filename\n",
    "\n",
    "    def prepare_data(self):\n",
    "        if not (self.path).exists():\n",
    "            content = requests.get(self.url + self.filename).content\n",
    "            self.path.open(\"wb\").write(content)\n",
    "\n",
    "    def setup(self):\n",
    "        with gzip.open(self.path, \"rb\") as f:\n",
    "            ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
    "\n",
    "        x_train, y_train, x_valid, y_valid = map(\n",
    "            torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    "            )\n",
    "        \n",
    "        self.train_ds = BaseDataset(x_train, y_train, transform=push_to_device, target_transform=push_to_device)\n",
    "        self.valid_ds = BaseDataset(x_valid, y_valid, transform=push_to_device, target_transform=push_to_device)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_ds, batch_size=self.bs, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.valid_ds, batch_size=2 * self.bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self: nn.Module, datamodule):\n",
    "    datamodule.prepare_data()\n",
    "    datamodule.setup()\n",
    "\n",
    "    val_dataloader = datamodule.val_dataloader()\n",
    "    \n",
    "    self.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_func(self(xb), yb) for xb, yb in val_dataloader)\n",
    "\n",
    "    print(\"before start of training:\", valid_loss / len(val_dataloader))\n",
    "\n",
    "    opt = configure_optimizer(self)\n",
    "    train_dataloader = datamodule.train_dataloader()\n",
    "    for epoch in range(epochs):\n",
    "        self.train()\n",
    "        for xb, yb in train_dataloader:\n",
    "            pred = self(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_loss = sum(loss_func(self(xb), yb) for xb, yb in val_dataloader)\n",
    "\n",
    "        print(epoch, valid_loss / len(val_dataloader))\n",
    "\n",
    "\n",
    "MNISTLogistic.fit = fit\n",
    "MLP.fit = fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before start of training: tensor(2.3047, device='cuda:0')\n",
      "0 tensor(0.1673, device='cuda:0')\n",
      "1 tensor(0.1168, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model = MLP(data_config)\n",
    "model.to(device)\n",
    "\n",
    "datamodule = MNISTDataModule(dir=path, bs=32)\n",
    "\n",
    "model.fit(datamodule=datamodule)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "### üåü Try out different hyperparameters for the `MLP` and for training.\n",
    "\n",
    "Can you get a final `valid`ation `acc`uracy of 98%?\n",
    "Can you get to 95% 2x faster than the baseline `MLP`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before start of training: tensor(2.3080, device='cuda:0')\n",
      "0 tensor(0.1649, device='cuda:0')\n",
      "1 tensor(0.1111, device='cuda:0')\n",
      "CPU times: user 21.8 s, sys: 1.71 s, total: 23.5 s\n",
      "Wall time: 23.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9677, device='cuda:0')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "from argparse import Namespace  # you'll need this\n",
    "\n",
    "args = None  # edit this\n",
    "\n",
    "epochs = 5  # used in fit\n",
    "bs = 32  # used by the DataModule\n",
    "\n",
    "\n",
    "# used in fit, play around with this if you'd like\n",
    "def configure_optimizer(model: nn.Module) -> optim.Optimizer:\n",
    "    return optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "\n",
    "model = MLP(data_config, args=args)\n",
    "model.to(device)\n",
    "\n",
    "datamodule = MNISTDataModule(dir=path, bs=bs)\n",
    "\n",
    "model.fit(datamodule=datamodule)\n",
    "\n",
    "val_dataloader = datamodule.val_dataloader()\n",
    "valid_acc = sum(accuracy(model(xb), yb) for xb, yb in val_dataloader) / len(val_dataloader)\n",
    "valid_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsdl-text-recognizer-2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd45800261f6757616163cab2ac15de492f098dcc7245a9ac63e943c300526a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
